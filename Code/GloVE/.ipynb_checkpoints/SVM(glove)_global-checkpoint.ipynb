{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glove import Corpus, Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Glove.load('../../Dataset/glove.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../Dataset/global_database_figer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFT_data=pd.read_csv('../../Dataset/global_MFT_dataset.csv')\n",
    "LFT_data=pd.read_csv('../../Dataset/global_LFT_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2610156"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(MFT_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence_ID</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>fine_grain</th>\n",
       "      <th>sentence</th>\n",
       "      <th>global coarse grained</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>44</td>\n",
       "      <td>Locomotion No. 1</td>\n",
       "      <td>['/train']</td>\n",
       "      <td>The first 0-4-0 to use coupling rods was Locom...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>44</td>\n",
       "      <td>Stockton and Darlington Railway</td>\n",
       "      <td>['/rail/railway', '/organization', '/organizat...</td>\n",
       "      <td>The first 0-4-0 to use coupling rods was Locom...</td>\n",
       "      <td>rail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>53</td>\n",
       "      <td>East Coast Main Trunk Railway</td>\n",
       "      <td>['/rail/railway', '/location', '/rail']</td>\n",
       "      <td>One such locomotive , built by Peckett and Son...</td>\n",
       "      <td>rail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>56</td>\n",
       "      <td>Midland Railway 2228 Class</td>\n",
       "      <td>['/train']</td>\n",
       "      <td>Examples have included the LSWR O2 Class , Mid...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>56</td>\n",
       "      <td>LSWR M7 Class</td>\n",
       "      <td>['/train']</td>\n",
       "      <td>Examples have included the LSWR O2 Class , Mid...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92</td>\n",
       "      <td>56</td>\n",
       "      <td>Caledonian Railway 439 Class</td>\n",
       "      <td>['/train']</td>\n",
       "      <td>Examples have included the LSWR O2 Class , Mid...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>93</td>\n",
       "      <td>57</td>\n",
       "      <td>Midland Railway 2228 Class</td>\n",
       "      <td>['/train']</td>\n",
       "      <td>The last British design of 0-4-4T were the LMS...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>108</td>\n",
       "      <td>64</td>\n",
       "      <td>Curt Gowdy Media Award</td>\n",
       "      <td>['/award']</td>\n",
       "      <td>His work has appeared in the Best American Spo...</td>\n",
       "      <td>award</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>119</td>\n",
       "      <td>71</td>\n",
       "      <td>4-6-2T</td>\n",
       "      <td>['/train']</td>\n",
       "      <td>This three-cylindered pattern had begun with H...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>120</td>\n",
       "      <td>71</td>\n",
       "      <td>4-4-4T</td>\n",
       "      <td>['/train']</td>\n",
       "      <td>This three-cylindered pattern had begun with H...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>127</td>\n",
       "      <td>76</td>\n",
       "      <td>Pure Food and Drug Act</td>\n",
       "      <td>['/law']</td>\n",
       "      <td>The book goes on to state that the Pure Food a...</td>\n",
       "      <td>law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>163</td>\n",
       "      <td>97</td>\n",
       "      <td>1 Ceres</td>\n",
       "      <td>['/astral_body']</td>\n",
       "      <td>Discovered on October 8 , 1969 , it was named ...</td>\n",
       "      <td>astral_body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>170</td>\n",
       "      <td>101</td>\n",
       "      <td>main-belt</td>\n",
       "      <td>['/astral_body']</td>\n",
       "      <td>10009 Hirosetanso ( 1977 EA6 ) is a main-belt ...</td>\n",
       "      <td>astral_body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>218</td>\n",
       "      <td>126</td>\n",
       "      <td>iTunes</td>\n",
       "      <td>['/internet/website', '/internet']</td>\n",
       "      <td>The song is set to be released as Rawlins ' de...</td>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>220</td>\n",
       "      <td>128</td>\n",
       "      <td>clinical depression</td>\n",
       "      <td>['/disease']</td>\n",
       "      <td>On July 25 , 1972 , just over two weeks after ...</td>\n",
       "      <td>disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>245</td>\n",
       "      <td>143</td>\n",
       "      <td>Ramadan</td>\n",
       "      <td>['/time']</td>\n",
       "      <td>During its run in London , the exhibition was ...</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>267</td>\n",
       "      <td>154</td>\n",
       "      <td>main-belt</td>\n",
       "      <td>['/astral_body']</td>\n",
       "      <td>10039 Keet Seel ( 1984 LK ) is a main-belt ast...</td>\n",
       "      <td>astral_body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>284</td>\n",
       "      <td>161</td>\n",
       "      <td>outer main-belt</td>\n",
       "      <td>['/astral_body']</td>\n",
       "      <td>10099 Glazebrook ( 1991 VB9 ) is an outer main...</td>\n",
       "      <td>astral_body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>322</td>\n",
       "      <td>181</td>\n",
       "      <td>Montreal Metro</td>\n",
       "      <td>['/transit']</td>\n",
       "      <td>It is also linked to Cremazie Station of the M...</td>\n",
       "      <td>transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>364</td>\n",
       "      <td>207</td>\n",
       "      <td>Kanal 5</td>\n",
       "      <td>['/broadcast/tv_channel', '/broadcast_network'...</td>\n",
       "      <td>100 hojdare ( \" 100 Highlights \" ) was a Swedi...</td>\n",
       "      <td>broadcast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>400</td>\n",
       "      <td>227</td>\n",
       "      <td>euro</td>\n",
       "      <td>['/finance/currency', '/finance']</td>\n",
       "      <td>Most of the world 's currencies are divided in...</td>\n",
       "      <td>finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>407</td>\n",
       "      <td>231</td>\n",
       "      <td>Orion NebulaRevised</td>\n",
       "      <td>['/astral_body']</td>\n",
       "      <td>Pm - 24 light years - Diameter of the Orion Ne...</td>\n",
       "      <td>astral_body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>421</td>\n",
       "      <td>235</td>\n",
       "      <td>Billboard Music Awards</td>\n",
       "      <td>['/award']</td>\n",
       "      <td>The song won Waters a billboard award for , \" ...</td>\n",
       "      <td>award</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>457</td>\n",
       "      <td>258</td>\n",
       "      <td>V-E Day</td>\n",
       "      <td>['/time', '/event']</td>\n",
       "      <td>Shifting to Goppingen on 30 April , the Divisi...</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>485</td>\n",
       "      <td>273</td>\n",
       "      <td>champagne</td>\n",
       "      <td>['/food']</td>\n",
       "      <td>In addition , guests were given champagne dona...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>502</td>\n",
       "      <td>281</td>\n",
       "      <td>GO !</td>\n",
       "      <td>['/broadcast_network']</td>\n",
       "      <td>Neil \" Wilko \" Wilcock - Was afternoon announc...</td>\n",
       "      <td>broadcast_network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>506</td>\n",
       "      <td>283</td>\n",
       "      <td>outer main-belt</td>\n",
       "      <td>['/astral_body']</td>\n",
       "      <td>10148 Shirase ( 1994 GR9 ) is an outer main-be...</td>\n",
       "      <td>astral_body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>508</td>\n",
       "      <td>284</td>\n",
       "      <td>main-belt</td>\n",
       "      <td>['/astral_body']</td>\n",
       "      <td>10153 Goldman ( 1994 UB ) is a main-belt aster...</td>\n",
       "      <td>astral_body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>515</td>\n",
       "      <td>287</td>\n",
       "      <td>Ojima</td>\n",
       "      <td>['/astral_body']</td>\n",
       "      <td>10162 Issunboushi ( 1995 AL ) is a main-belt a...</td>\n",
       "      <td>astral_body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>525</td>\n",
       "      <td>294</td>\n",
       "      <td>main-belt</td>\n",
       "      <td>['/astral_body']</td>\n",
       "      <td>10182 Junkobiwaki ( 1996 FL5 ) is a main-belt ...</td>\n",
       "      <td>astral_body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80100</th>\n",
       "      <td>2689328</td>\n",
       "      <td>1505236</td>\n",
       "      <td>Lisp programming language</td>\n",
       "      <td>['/computer', '/computer/programming_language']</td>\n",
       "      <td>Using a dialect of the Lisp programming langua...</td>\n",
       "      <td>computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80101</th>\n",
       "      <td>2689329</td>\n",
       "      <td>1505236</td>\n",
       "      <td>Scheme</td>\n",
       "      <td>['/computer', '/computer/programming_language']</td>\n",
       "      <td>Using a dialect of the Lisp programming langua...</td>\n",
       "      <td>computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80102</th>\n",
       "      <td>2689334</td>\n",
       "      <td>1505240</td>\n",
       "      <td>COBOL</td>\n",
       "      <td>['/computer', '/computer/programming_language']</td>\n",
       "      <td>In the 1980s IBM researcher Harlan Mills overs...</td>\n",
       "      <td>computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80103</th>\n",
       "      <td>2689365</td>\n",
       "      <td>1505259</td>\n",
       "      <td>pyramidal tract</td>\n",
       "      <td>['/body_part']</td>\n",
       "      <td>It is found in patients with pyramidal tract l...</td>\n",
       "      <td>body_part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80104</th>\n",
       "      <td>2689441</td>\n",
       "      <td>1505300</td>\n",
       "      <td>South Gippsland line</td>\n",
       "      <td>['/metropolitan_transit', '/metropolitan_trans...</td>\n",
       "      <td>The line opened in June , 1922 , branching off...</td>\n",
       "      <td>metropolitan_transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80105</th>\n",
       "      <td>2689518</td>\n",
       "      <td>1505348</td>\n",
       "      <td>eggs</td>\n",
       "      <td>['/food']</td>\n",
       "      <td>The other student experiment was to fly 32 chi...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80106</th>\n",
       "      <td>2689538</td>\n",
       "      <td>1505359</td>\n",
       "      <td>red</td>\n",
       "      <td>['/visual_art/color', '/visual_art']</td>\n",
       "      <td>Astronauts Thomas D. Akers and Kathryn C. Thor...</td>\n",
       "      <td>visual_art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80107</th>\n",
       "      <td>2689565</td>\n",
       "      <td>1505377</td>\n",
       "      <td>Metropolis Management Act 1855</td>\n",
       "      <td>['/law']</td>\n",
       "      <td>It was formed by the Metropolis Management Act...</td>\n",
       "      <td>law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80108</th>\n",
       "      <td>2689572</td>\n",
       "      <td>1505383</td>\n",
       "      <td>plague</td>\n",
       "      <td>['/event/natural_disaster', '/event']</td>\n",
       "      <td>It has been suggested that the picture was mad...</td>\n",
       "      <td>disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80109</th>\n",
       "      <td>2689574</td>\n",
       "      <td>1505385</td>\n",
       "      <td>Macbeth</td>\n",
       "      <td>['/person/monarch', '/person/politician', '/pe...</td>\n",
       "      <td>It is from these that we know Macbeth , the Ki...</td>\n",
       "      <td>play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80110</th>\n",
       "      <td>2689590</td>\n",
       "      <td>1505393</td>\n",
       "      <td>chicken</td>\n",
       "      <td>['/livingthing', '/livingthing/animal', '/livi...</td>\n",
       "      <td>The seminary fed itself with an orchard , a ch...</td>\n",
       "      <td>livingthing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80111</th>\n",
       "      <td>2689757</td>\n",
       "      <td>1505491</td>\n",
       "      <td>National Post</td>\n",
       "      <td>['/news_agency', '/written_work']</td>\n",
       "      <td>Canada 's National Post newspaper ran the head...</td>\n",
       "      <td>news_agency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80112</th>\n",
       "      <td>2689864</td>\n",
       "      <td>1505558</td>\n",
       "      <td>Macavity Award</td>\n",
       "      <td>['/award']</td>\n",
       "      <td>He earned six other Edgar nominations , most r...</td>\n",
       "      <td>award</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80113</th>\n",
       "      <td>2689865</td>\n",
       "      <td>1505558</td>\n",
       "      <td>Agatha Award</td>\n",
       "      <td>['/award']</td>\n",
       "      <td>He earned six other Edgar nominations , most r...</td>\n",
       "      <td>award</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80114</th>\n",
       "      <td>2689878</td>\n",
       "      <td>1505562</td>\n",
       "      <td>Publishers Weekly</td>\n",
       "      <td>['/news_agency', '/written_work']</td>\n",
       "      <td>The book has been given full reviews in a numb...</td>\n",
       "      <td>news_agency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80115</th>\n",
       "      <td>2689897</td>\n",
       "      <td>1505569</td>\n",
       "      <td>Up From Paradise</td>\n",
       "      <td>['/play', '/written_work']</td>\n",
       "      <td>Since its inception , the MTLab has presented ...</td>\n",
       "      <td>play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80116</th>\n",
       "      <td>2689911</td>\n",
       "      <td>1505578</td>\n",
       "      <td>Secret treaty of Dover</td>\n",
       "      <td>['/law']</td>\n",
       "      <td>( 1670 ) : Secret treaty of Dover between Char...</td>\n",
       "      <td>law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80117</th>\n",
       "      <td>2689933</td>\n",
       "      <td>1505590</td>\n",
       "      <td>eBay</td>\n",
       "      <td>['/internet', '/person/engineer', '/internet/w...</td>\n",
       "      <td>nancyboy 's were created in 2009 and auctioned...</td>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80118</th>\n",
       "      <td>2690027</td>\n",
       "      <td>1505636</td>\n",
       "      <td>Lambda Literary Award</td>\n",
       "      <td>['/award']</td>\n",
       "      <td>Stuck Rubber Baby was nominated for the Americ...</td>\n",
       "      <td>award</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80119</th>\n",
       "      <td>2690040</td>\n",
       "      <td>1505642</td>\n",
       "      <td>Champion</td>\n",
       "      <td>['/product/car', '/product']</td>\n",
       "      <td>From the 1920s to the 1930s , the South Bend c...</td>\n",
       "      <td>award</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80120</th>\n",
       "      <td>2690050</td>\n",
       "      <td>1505648</td>\n",
       "      <td>Champion</td>\n",
       "      <td>['/product/car', '/product']</td>\n",
       "      <td>The Starlight coupe was a unique 2-door body s...</td>\n",
       "      <td>award</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80121</th>\n",
       "      <td>2690071</td>\n",
       "      <td>1505654</td>\n",
       "      <td>Halloween</td>\n",
       "      <td>['/art', '/art/film']</td>\n",
       "      <td>It is a spoof of slasher horror films such as ...</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80122</th>\n",
       "      <td>2690083</td>\n",
       "      <td>1505661</td>\n",
       "      <td>Oslo Metro</td>\n",
       "      <td>['/transit']</td>\n",
       "      <td>It also contains one of the entrances to Natio...</td>\n",
       "      <td>transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80123</th>\n",
       "      <td>2690085</td>\n",
       "      <td>1505661</td>\n",
       "      <td>Drammen Line</td>\n",
       "      <td>['/metropolitan_transit', '/metropolitan_trans...</td>\n",
       "      <td>It also contains one of the entrances to Natio...</td>\n",
       "      <td>metropolitan_transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80124</th>\n",
       "      <td>2690092</td>\n",
       "      <td>1505667</td>\n",
       "      <td>National Pacemaker Award</td>\n",
       "      <td>['/award']</td>\n",
       "      <td>\" StudLife \" , as it is nicknamed by students ...</td>\n",
       "      <td>award</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80125</th>\n",
       "      <td>2690112</td>\n",
       "      <td>1505678</td>\n",
       "      <td>May Day</td>\n",
       "      <td>['/time']</td>\n",
       "      <td>SDS chapters , such as at Brandeis , Connectic...</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80126</th>\n",
       "      <td>2690150</td>\n",
       "      <td>1505700</td>\n",
       "      <td>Set</td>\n",
       "      <td>['/title']</td>\n",
       "      <td>In the second semester , the production studen...</td>\n",
       "      <td>god</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80127</th>\n",
       "      <td>2690154</td>\n",
       "      <td>1505703</td>\n",
       "      <td>Pulitzer Prize-winning</td>\n",
       "      <td>['/award']</td>\n",
       "      <td>Martha O'Dell ( Christine Lahti ) is a Pulitze...</td>\n",
       "      <td>award</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80128</th>\n",
       "      <td>2690201</td>\n",
       "      <td>1505725</td>\n",
       "      <td>Allmusic</td>\n",
       "      <td>['/internet/website', '/internet']</td>\n",
       "      <td>The Allmusic review by Scott Yanow awarded the...</td>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80129</th>\n",
       "      <td>2690230</td>\n",
       "      <td>1505740</td>\n",
       "      <td>allergy</td>\n",
       "      <td>['/disease']</td>\n",
       "      <td>Participants with a drug allergy or allergy to...</td>\n",
       "      <td>disease</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80130 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  sentence_ID                      entity_name  \\\n",
       "0              65           44                 Locomotion No. 1   \n",
       "1              67           44  Stockton and Darlington Railway   \n",
       "2              86           53    East Coast Main Trunk Railway   \n",
       "3              90           56       Midland Railway 2228 Class   \n",
       "4              91           56                    LSWR M7 Class   \n",
       "5              92           56     Caledonian Railway 439 Class   \n",
       "6              93           57       Midland Railway 2228 Class   \n",
       "7             108           64           Curt Gowdy Media Award   \n",
       "8             119           71                           4-6-2T   \n",
       "9             120           71                           4-4-4T   \n",
       "10            127           76           Pure Food and Drug Act   \n",
       "11            163           97                          1 Ceres   \n",
       "12            170          101                        main-belt   \n",
       "13            218          126                           iTunes   \n",
       "14            220          128              clinical depression   \n",
       "15            245          143                          Ramadan   \n",
       "16            267          154                        main-belt   \n",
       "17            284          161                  outer main-belt   \n",
       "18            322          181                   Montreal Metro   \n",
       "19            364          207                          Kanal 5   \n",
       "20            400          227                             euro   \n",
       "21            407          231              Orion NebulaRevised   \n",
       "22            421          235           Billboard Music Awards   \n",
       "23            457          258                          V-E Day   \n",
       "24            485          273                        champagne   \n",
       "25            502          281                             GO !   \n",
       "26            506          283                  outer main-belt   \n",
       "27            508          284                        main-belt   \n",
       "28            515          287                            Ojima   \n",
       "29            525          294                        main-belt   \n",
       "...           ...          ...                              ...   \n",
       "80100     2689328      1505236        Lisp programming language   \n",
       "80101     2689329      1505236                           Scheme   \n",
       "80102     2689334      1505240                            COBOL   \n",
       "80103     2689365      1505259                  pyramidal tract   \n",
       "80104     2689441      1505300             South Gippsland line   \n",
       "80105     2689518      1505348                             eggs   \n",
       "80106     2689538      1505359                              red   \n",
       "80107     2689565      1505377   Metropolis Management Act 1855   \n",
       "80108     2689572      1505383                           plague   \n",
       "80109     2689574      1505385                          Macbeth   \n",
       "80110     2689590      1505393                          chicken   \n",
       "80111     2689757      1505491                    National Post   \n",
       "80112     2689864      1505558                   Macavity Award   \n",
       "80113     2689865      1505558                     Agatha Award   \n",
       "80114     2689878      1505562                Publishers Weekly   \n",
       "80115     2689897      1505569                 Up From Paradise   \n",
       "80116     2689911      1505578           Secret treaty of Dover   \n",
       "80117     2689933      1505590                             eBay   \n",
       "80118     2690027      1505636            Lambda Literary Award   \n",
       "80119     2690040      1505642                         Champion   \n",
       "80120     2690050      1505648                         Champion   \n",
       "80121     2690071      1505654                        Halloween   \n",
       "80122     2690083      1505661                       Oslo Metro   \n",
       "80123     2690085      1505661                     Drammen Line   \n",
       "80124     2690092      1505667         National Pacemaker Award   \n",
       "80125     2690112      1505678                          May Day   \n",
       "80126     2690150      1505700                              Set   \n",
       "80127     2690154      1505703           Pulitzer Prize-winning   \n",
       "80128     2690201      1505725                         Allmusic   \n",
       "80129     2690230      1505740                          allergy   \n",
       "\n",
       "                                              fine_grain  \\\n",
       "0                                             ['/train']   \n",
       "1      ['/rail/railway', '/organization', '/organizat...   \n",
       "2                ['/rail/railway', '/location', '/rail']   \n",
       "3                                             ['/train']   \n",
       "4                                             ['/train']   \n",
       "5                                             ['/train']   \n",
       "6                                             ['/train']   \n",
       "7                                             ['/award']   \n",
       "8                                             ['/train']   \n",
       "9                                             ['/train']   \n",
       "10                                              ['/law']   \n",
       "11                                      ['/astral_body']   \n",
       "12                                      ['/astral_body']   \n",
       "13                    ['/internet/website', '/internet']   \n",
       "14                                          ['/disease']   \n",
       "15                                             ['/time']   \n",
       "16                                      ['/astral_body']   \n",
       "17                                      ['/astral_body']   \n",
       "18                                          ['/transit']   \n",
       "19     ['/broadcast/tv_channel', '/broadcast_network'...   \n",
       "20                     ['/finance/currency', '/finance']   \n",
       "21                                      ['/astral_body']   \n",
       "22                                            ['/award']   \n",
       "23                                   ['/time', '/event']   \n",
       "24                                             ['/food']   \n",
       "25                                ['/broadcast_network']   \n",
       "26                                      ['/astral_body']   \n",
       "27                                      ['/astral_body']   \n",
       "28                                      ['/astral_body']   \n",
       "29                                      ['/astral_body']   \n",
       "...                                                  ...   \n",
       "80100    ['/computer', '/computer/programming_language']   \n",
       "80101    ['/computer', '/computer/programming_language']   \n",
       "80102    ['/computer', '/computer/programming_language']   \n",
       "80103                                     ['/body_part']   \n",
       "80104  ['/metropolitan_transit', '/metropolitan_trans...   \n",
       "80105                                          ['/food']   \n",
       "80106               ['/visual_art/color', '/visual_art']   \n",
       "80107                                           ['/law']   \n",
       "80108              ['/event/natural_disaster', '/event']   \n",
       "80109  ['/person/monarch', '/person/politician', '/pe...   \n",
       "80110  ['/livingthing', '/livingthing/animal', '/livi...   \n",
       "80111                  ['/news_agency', '/written_work']   \n",
       "80112                                         ['/award']   \n",
       "80113                                         ['/award']   \n",
       "80114                  ['/news_agency', '/written_work']   \n",
       "80115                         ['/play', '/written_work']   \n",
       "80116                                           ['/law']   \n",
       "80117  ['/internet', '/person/engineer', '/internet/w...   \n",
       "80118                                         ['/award']   \n",
       "80119                       ['/product/car', '/product']   \n",
       "80120                       ['/product/car', '/product']   \n",
       "80121                              ['/art', '/art/film']   \n",
       "80122                                       ['/transit']   \n",
       "80123  ['/metropolitan_transit', '/metropolitan_trans...   \n",
       "80124                                         ['/award']   \n",
       "80125                                          ['/time']   \n",
       "80126                                         ['/title']   \n",
       "80127                                         ['/award']   \n",
       "80128                 ['/internet/website', '/internet']   \n",
       "80129                                       ['/disease']   \n",
       "\n",
       "                                                sentence global coarse grained  \n",
       "0      The first 0-4-0 to use coupling rods was Locom...                 train  \n",
       "1      The first 0-4-0 to use coupling rods was Locom...                  rail  \n",
       "2      One such locomotive , built by Peckett and Son...                  rail  \n",
       "3      Examples have included the LSWR O2 Class , Mid...                 train  \n",
       "4      Examples have included the LSWR O2 Class , Mid...                 train  \n",
       "5      Examples have included the LSWR O2 Class , Mid...                 train  \n",
       "6      The last British design of 0-4-4T were the LMS...                 train  \n",
       "7      His work has appeared in the Best American Spo...                 award  \n",
       "8      This three-cylindered pattern had begun with H...                 train  \n",
       "9      This three-cylindered pattern had begun with H...                 train  \n",
       "10     The book goes on to state that the Pure Food a...                   law  \n",
       "11     Discovered on October 8 , 1969 , it was named ...           astral_body  \n",
       "12     10009 Hirosetanso ( 1977 EA6 ) is a main-belt ...           astral_body  \n",
       "13     The song is set to be released as Rawlins ' de...              internet  \n",
       "14     On July 25 , 1972 , just over two weeks after ...               disease  \n",
       "15     During its run in London , the exhibition was ...                  time  \n",
       "16     10039 Keet Seel ( 1984 LK ) is a main-belt ast...           astral_body  \n",
       "17     10099 Glazebrook ( 1991 VB9 ) is an outer main...           astral_body  \n",
       "18     It is also linked to Cremazie Station of the M...               transit  \n",
       "19     100 hojdare ( \" 100 Highlights \" ) was a Swedi...             broadcast  \n",
       "20     Most of the world 's currencies are divided in...               finance  \n",
       "21     Pm - 24 light years - Diameter of the Orion Ne...           astral_body  \n",
       "22     The song won Waters a billboard award for , \" ...                 award  \n",
       "23     Shifting to Goppingen on 30 April , the Divisi...                  time  \n",
       "24     In addition , guests were given champagne dona...                  food  \n",
       "25     Neil \" Wilko \" Wilcock - Was afternoon announc...     broadcast_network  \n",
       "26     10148 Shirase ( 1994 GR9 ) is an outer main-be...           astral_body  \n",
       "27     10153 Goldman ( 1994 UB ) is a main-belt aster...           astral_body  \n",
       "28     10162 Issunboushi ( 1995 AL ) is a main-belt a...           astral_body  \n",
       "29     10182 Junkobiwaki ( 1996 FL5 ) is a main-belt ...           astral_body  \n",
       "...                                                  ...                   ...  \n",
       "80100  Using a dialect of the Lisp programming langua...              computer  \n",
       "80101  Using a dialect of the Lisp programming langua...              computer  \n",
       "80102  In the 1980s IBM researcher Harlan Mills overs...              computer  \n",
       "80103  It is found in patients with pyramidal tract l...             body_part  \n",
       "80104  The line opened in June , 1922 , branching off...  metropolitan_transit  \n",
       "80105  The other student experiment was to fly 32 chi...                  food  \n",
       "80106  Astronauts Thomas D. Akers and Kathryn C. Thor...            visual_art  \n",
       "80107  It was formed by the Metropolis Management Act...                   law  \n",
       "80108  It has been suggested that the picture was mad...               disease  \n",
       "80109  It is from these that we know Macbeth , the Ki...                  play  \n",
       "80110  The seminary fed itself with an orchard , a ch...           livingthing  \n",
       "80111  Canada 's National Post newspaper ran the head...           news_agency  \n",
       "80112  He earned six other Edgar nominations , most r...                 award  \n",
       "80113  He earned six other Edgar nominations , most r...                 award  \n",
       "80114  The book has been given full reviews in a numb...           news_agency  \n",
       "80115  Since its inception , the MTLab has presented ...                  play  \n",
       "80116  ( 1670 ) : Secret treaty of Dover between Char...                   law  \n",
       "80117  nancyboy 's were created in 2009 and auctioned...              internet  \n",
       "80118  Stuck Rubber Baby was nominated for the Americ...                 award  \n",
       "80119  From the 1920s to the 1930s , the South Bend c...                 award  \n",
       "80120  The Starlight coupe was a unique 2-door body s...                 award  \n",
       "80121  It is a spoof of slasher horror films such as ...                  time  \n",
       "80122  It also contains one of the entrances to Natio...               transit  \n",
       "80123  It also contains one of the entrances to Natio...  metropolitan_transit  \n",
       "80124  \" StudLife \" , as it is nicknamed by students ...                 award  \n",
       "80125  SDS chapters , such as at Brandeis , Connectic...                  time  \n",
       "80126  In the second semester , the production studen...                   god  \n",
       "80127  Martha O'Dell ( Christine Lahti ) is a Pulitze...                 award  \n",
       "80128  The Allmusic review by Scott Yanow awarded the...              internet  \n",
       "80129  Participants with a drug allergy or allergy to...               disease  \n",
       "\n",
       "[80130 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFT_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(dataset):\n",
    "    \n",
    "    X, y = np.asarray(dataset['sentence']), np.asarray(dataset['global coarse grained'])\n",
    "    label_map = {cat:index for index,cat in enumerate(np.unique(y))}\n",
    "    y_prep = np.asarray([label_map[l] for l in y])\n",
    "    x_tokenized = [[w for w in sentence.split(\" \") if w != \"\"] for sentence in X]\n",
    "   \n",
    "    return x_tokenized, y_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequencer():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 all_words,\n",
    "                 max_words,\n",
    "                 seq_len,\n",
    "                 model\n",
    "                ):\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.glove_model = model\n",
    "        \"\"\"\n",
    "        temp_vocab = Vocab which has all the unique words\n",
    "        self.vocab = Our last vocab which has only most used N words.\n",
    "    \n",
    "        \"\"\"\n",
    "        temp_vocab = list(set(all_words))\n",
    "        self.vocab = []\n",
    "        self.word_cnts = {}\n",
    "        \"\"\"\n",
    "        Now we'll create a hash map (dict) which includes words and their occurencies\n",
    "        \"\"\"\n",
    "        for word in temp_vocab:\n",
    "            # 0 does not have a meaning, you can add the word to the list\n",
    "            # or something different.\n",
    "            count = len([0 for w in all_words if w == word])\n",
    "            self.word_cnts[word] = count\n",
    "            counts = list(self.word_cnts.values())\n",
    "            indexes = list(range(len(counts)))\n",
    "        \n",
    "        # Now we'll sort counts and while sorting them also will sort indexes.\n",
    "        # We'll use those indexes to find most used N word.\n",
    "        cnt = 0\n",
    "        while cnt + 1 != len(counts):\n",
    "            cnt = 0\n",
    "            for i in range(len(counts)-1):\n",
    "                if counts[i] < counts[i+1]:\n",
    "                    counts[i+1],counts[i] = counts[i],counts[i+1]\n",
    "                    indexes[i],indexes[i+1] = indexes[i+1],indexes[i]\n",
    "                else:\n",
    "                    cnt += 1\n",
    "        \n",
    "        for ind in indexes[:max_words]:\n",
    "            self.vocab.append(temp_vocab[ind])\n",
    "                    \n",
    "    def textToVector(self,text):\n",
    "        # First we need to split the text into its tokens and learn the length\n",
    "        # If length is shorter than the max len we'll add some spaces (100D vectors which has only zero values)\n",
    "        # If it's longer than the max len we'll trim from the end.\n",
    "        tokens = text.split()\n",
    "        len_v = len(tokens)-1 if len(tokens) < self.seq_len else self.seq_len-1\n",
    "        vec = []\n",
    "        for tok in tokens[:len_v]:\n",
    "            try:\n",
    "                dict_index = self.glove_model.dictionary[tok]\n",
    "                vec.append(self.glove_model.word_vectors[dict_index])\n",
    "            except Exception as E:\n",
    "                pass\n",
    "        \n",
    "        last_pieces = self.seq_len - len(vec)\n",
    "        for i in range(last_pieces):\n",
    "            vec.append(np.zeros(5,))\n",
    "        \n",
    "        return np.asarray(vec).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. LFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tokenized, y_prep = preprocessing(LFT_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Entities = np.asarray(LFT_data['entity_name'])\n",
    "e_tokenized = [[w for w in str(e).split(\" \") if w != \"\"] for e in Entities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_sequencer = Sequencer(all_words = [token for seq in e_tokenized for token in seq],\n",
    "              max_words = 1200,\n",
    "              seq_len = 15,\n",
    "              model = model\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_vecs = np.asarray([entity_sequencer.textToVector(\" \".join(seq)) for seq in e_tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of variance ratios:  0.9979625196690795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_model = PCA(n_components=50)\n",
    "pca_model.fit(e_vecs)\n",
    "print(\"Sum of variance ratios: \",sum(pca_model.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_comps = pca_model.transform(e_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64104, 50)\n",
      "(16026, 50)\n",
      "(64104,)\n",
      "(16026,)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(e_comps,y_prep,test_size=0.2,random_state=42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evelyn/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evelyn/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06481030370019449"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14389117683763883"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10286950160921395"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFT_data = MFT_data.sample(n=80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tokenized, y_prep = preprocessing(MFT_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Entities = np.asarray(MFT_data['entity_name'])\n",
    "e_tokenized = [[w for w in str(e).split(\" \") if w != \"\"] for e in Entities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_sequencer = Sequencer(all_words = [token for seq in e_tokenized for token in seq],\n",
    "              max_words = 1200,\n",
    "              seq_len = 15,\n",
    "              model = model\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_vecs = np.asarray([entity_sequencer.textToVector(\" \".join(seq)) for seq in e_tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of variance ratios:  0.9991309865111957\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_model = PCA(n_components=50)\n",
    "pca_model.fit(e_vecs)\n",
    "print(\"Sum of variance ratios: \",sum(pca_model.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_comps = pca_model.transform(e_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64000, 50)\n",
      "(16000, 50)\n",
      "(64000,)\n",
      "(16000,)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(e_comps,y_prep,test_size=0.2,random_state=42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evelyn/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evelyn/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05122359929729358"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37431249999999994"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24296450411253256"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(n=80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tokenized, y_prep = preprocessing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Entities = np.asarray(data['entity_name'])\n",
    "e_tokenized = [[w for w in e.split(\" \") if w != \"\"] for e in Entities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_sequencer = Sequencer(all_words = [token for seq in e_tokenized for token in seq],\n",
    "              max_words = 2000,\n",
    "              seq_len = 15,\n",
    "              model=model\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_vecs = np.asarray([entity_sequencer.textToVector(\" \".join(seq)) for seq in e_tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of variance ratios:  0.9988945537501375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_model = PCA(n_components=50)\n",
    "pca_model.fit(e_vecs)\n",
    "print(\"Sum of variance ratios: \",sum(pca_model.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_comps = pca_model.transform(e_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64000, 50)\n",
      "(16000, 50)\n",
      "(64000,)\n",
      "(16000,)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(e_comps,y_prep,test_size=0.2,random_state=42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evelyn/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evelyn/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.027302066823949867"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36175"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23436698492290417"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## similarity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('flows', 0.9969630371257711),\n",
       " ('small', 0.9962222153819585),\n",
       " ('cities', 0.9961364715164609),\n",
       " ('arterial', 0.9960630906625995)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('rail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('solely', 0.9988180636450562),\n",
       " ('wrestlers', 0.9986891198539983),\n",
       " ('pull', 0.998408863728595),\n",
       " ('property', 0.9982836630891359)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('internet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('motorsport', 0.9975584029264936),\n",
       " ('1402', 0.9964067786941028),\n",
       " ('crafts', 0.9955452556627562),\n",
       " ('7-3', 0.9952782237897274)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('biology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('caribbean', 0.9978722331539843),\n",
       " ('nigmatullin', 0.9965894879510891),\n",
       " ('mainland', 0.9964540417420519),\n",
       " ('nearby', 0.9952109594485312)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('transit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aground', 0.9985774845738553),\n",
       " ('news', 0.9984539884976539),\n",
       " ('sixes', 0.9976641848708611),\n",
       " ('apiece', 0.9966718402546354)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('broadcast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('privately', 0.9991001772717363),\n",
       " ('armed', 0.9990183672981497),\n",
       " ('terms', 0.9989140538581939),\n",
       " ('practice', 0.9986981883268019)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('newspaper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('annual', 0.9994483113795459),\n",
       " ('gr-33', 0.9989416045508036),\n",
       " ('fifth', 0.998240383849126),\n",
       " ('eighth', 0.9977599075306751)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('game')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
